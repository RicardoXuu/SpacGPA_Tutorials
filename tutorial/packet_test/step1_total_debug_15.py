
# %%
# 优化莫兰指数的计算逻辑
# 切换工作目录
import os
workdir = '/dta/ypxu/SpacGPA/Article_Info/Codes_For_SpacGPA_Reproducibility/'
os.chdir(workdir)
print('Current working directory:', os.getcwd())

# %%
# 加载必须的包
import numpy as np
import pandas as pd
import random
import time
import torch
import scanpy as sc
import anndata
import os
import gc
import copy
import matplotlib.pyplot as plt
import seaborn as sns

from reportlab.lib.pagesizes import letter
from reportlab.pdfgen import canvas
from PIL import Image
from matplotlib.path import Path
from scipy.spatial import ConvexHull
from skimage.transform import rotate

import SpacGPA as sg

# %%
# 读取数据
# The Visium_Mouse_Brain_Multi_Union_r3.ggm.h5 file contains the gene-gene interaction network
# All the data files are generated by the SpacGPA pipeline 
ggm = sg.load_ggm('data/Fig4/ggm_data/Visium_Mouse_Brain_Multi_Union_r3.ggm.h5')


# %%
# # 读取参与联合分析的其中2张visium数据集
# # 数据集1: CytAssist_FFPE_Mouse_Brain_Rep1
adata_in_1 = sc.read_visium("/dta/ypxu/ST_GGM/Raw_Datasets/visium/CytAssist_FFPE_Mouse_Brain_Rep1",
                       count_file="CytAssist_FFPE_Mouse_Brain_Rep1_filtered_feature_bc_matrix.h5")
adata_in_1.var_names = adata_in_1.var['gene_ids']
# Log-transform the data
sc.pp.normalize_total(adata_in_1,target_sum=1e4)
sc.pp.log1p(adata_in_1)

# 数据集2: CytAssist_FreshFrozen_Mouse_Brain_Rep2
adata_in_2 = sc.read_visium("/dta/ypxu/ST_GGM/Raw_Datasets/visium/V1_Adult_Mouse_Brain", 
                        count_file='V1_Adult_Mouse_Brain_filtered_feature_bc_matrix.h5')
adata_in_2.var_names = adata_in_2.var['gene_ids']
# Reset the coords
lib_id = list(adata_in_2.uns['spatial'].keys())[0]          
hires = adata_in_2.uns['spatial'][lib_id]['images']['hires']
lowres = adata_in_2.uns['spatial'][lib_id]['images']['lowres']
hires_flipped  = np.fliplr(hires)
lowres_flipped = np.fliplr(lowres)
sf = adata_in_2.uns['spatial'][lib_id]['scalefactors']['tissue_hires_scalef']
full_W = hires.shape[1] / sf          # ← fullres 图像宽度
x_full, y_full = adata_in_2.obsm['spatial'].T
x_mirror = (full_W - 1) - x_full      # 左右对称
adata_in_2.obsm['spatial'] = np.c_[x_mirror, y_full]
adata_in_2.uns['spatial'] = copy.deepcopy(adata_in_2.uns['spatial'])
adata_in_2.uns['spatial'][lib_id]['images']['hires']  = hires_flipped
adata_in_2.uns['spatial'][lib_id]['images']['lowres'] = lowres_flipped
# Log-transform the data
sc.pp.normalize_total(adata_in_2,target_sum=1e4)
sc.pp.log1p(adata_in_2)


# 读取用于验证的数据集
# 读取验证集1,visium数据集
adata_vi = sc.read_visium("/dta/ypxu/ST_GGM/Raw_Datasets/visium/CytAssist_FreshFrozen_Mouse_Brain_Rep2",
                       count_file="CytAssist_FreshFrozen_Mouse_Brain_Rep2_filtered_feature_bc_matrix.h5")
adata_vi.var_names = adata_vi.var['gene_ids']
adata_vi.var_names_make_unique()
# Reset the coords
lib_id = list(adata_vi.uns['spatial'].keys())[0]          
hires_img = adata_vi.uns['spatial'][lib_id]['images']['hires']
lowres_img = adata_vi.uns['spatial'][lib_id]['images']['lowres']
H, W, _ = hires_img.shape
hires_rot  = rotate(hires_img,  angle=-90, resize=True, preserve_range=True).astype(hires_img.dtype)
lowres_rot = rotate(lowres_img, angle=-90, resize=True, preserve_range=True).astype(lowres_img.dtype)
coords = adata_vi.obsm['spatial'].copy()
x, y = coords[:, 0], coords[:, 1]
W_full = coords[:, 0].max() - coords[:, 0].min()
H_full = coords[:, 1].max() - coords[:, 1].min()
x_new = H_full - y + adata_vi.uns['spatial'][lib_id]['scalefactors']['spot_diameter_fullres'] 
y_new = x
adata_vi.obsm['spatial'] = np.c_[x_new, y_new]
adata_vi.uns['spatial'] = copy.deepcopy(adata_vi.uns['spatial'])
adata_vi.uns['spatial'][lib_id]['images']['hires']  = hires_rot
adata_vi.uns['spatial'][lib_id]['images']['lowres'] = lowres_rot
sf = adata_vi.uns['spatial'][lib_id]['scalefactors']
sf['tissue_hires_scalef']  = sf['tissue_hires_scalef']
sf['tissue_lowres_scalef'] = sf['tissue_lowres_scalef']
# Log-transform the data
sc.pp.normalize_total(adata_vi,target_sum=1e4)
sc.pp.log1p(adata_vi)
# Remove spots outside the tissue
adata_vi = adata_vi[adata_vi.obsm['spatial'][:, 1] < 27500].copy()
adata_vi = adata_vi[adata_vi.obsm['spatial'][:, 1] > -5561].copy()

# 读取验证集2,visium_HD数据集
adata_hd = sc.read_visium("/dta/ypxu/ST_GGM/Raw_Datasets/visium_HD/Mouse_Brain_Fixed_Frozen/binned_outputs/square_016um/",
                       count_file="filtered_feature_bc_matrix.h5")
adata_hd.var_names = adata_hd.var['gene_ids']
adata_hd.var_names_make_unique()
# Reset the coords 
lib_id = list(adata_hd.uns['spatial'].keys())[0]          
hires_img = adata_hd.uns['spatial'][lib_id]['images']['hires']
lowres_img = adata_hd.uns['spatial'][lib_id]['images']['lowres']
H, W, _ = hires_img.shape                                  
hires_rot  = rotate(hires_img,  angle=-90, resize=True, preserve_range=True).astype(hires_img.dtype)
lowres_rot = rotate(lowres_img, angle=-90, resize=True, preserve_range=True).astype(lowres_img.dtype)
hires_new  = np.fliplr(hires_rot)
lowres_new = np.fliplr(lowres_rot)
H_rot, W_rot, _ = hires_rot.shape  
coords = adata_hd.obsm['spatial'].copy()
x, y = coords[:, 0], coords[:, 1]
x1 = y 
y1 = H - x + adata_hd.uns['spatial'][lib_id]['scalefactors']['spot_diameter_fullres']          
x2 = x1                       
y2 = W_rot - y1               
adata_hd.obsm['spatial'] = np.c_[x2, y2]
adata_hd.uns['spatial'] = copy.deepcopy(adata_hd.uns['spatial'])
adata_hd.uns['spatial'][lib_id]['images']['hires']  = hires_new
adata_hd.uns['spatial'][lib_id]['images']['lowres'] = lowres_new
sf = adata_hd.uns['spatial'][lib_id]['scalefactors']
sf['tissue_hires_scalef']  = sf['tissue_hires_scalef']
sf['tissue_lowres_scalef'] = sf['tissue_lowres_scalef']
# Log-transform the data
sc.pp.normalize_total(adata_hd, target_sum=1e4)
sc.pp.log1p(adata_hd)
# Remove spots outside the tissue
adata_hd = adata_hd[adata_hd.obsm['spatial'][:, 0] < 20800].copy()

# 读取验证数据集3，Xenium 5K数据集
adata_xe = sc.read_10x_h5('/dta/ypxu/ST_GGM/Raw_Datasets/Xenium/Mouse_Brain_Hemisphere_5K/cell_feature_matrix.h5')
adata_xe.var_names_make_unique()
adata_xe.var_names = adata_xe.var['gene_ids']
meta = pd.read_csv('/dta/ypxu/ST_GGM/Raw_Datasets/Xenium/Mouse_Brain_Hemisphere_5K/cells.csv.gz')
adata_xe.obs = meta
adata_xe.obsm['spatial'] = adata_xe.obs[['y_centroid','x_centroid']].values*[-1,-1]

sc.pp.log1p(adata_xe)

# 读取验证集4,scRNA-seq数据集
adata_sc = sc.read_h5ad('/dta/ypxu/ST_GGM/Raw_Datasets/Sc_Data/WMB-10Xv3/WMB-10Xv3-all-downsampled.h5ad')


# %%
# 计算模块表达量
sg.calculate_module_expression(adata_in_1,ggm)
sg.calculate_module_expression(adata_in_2,ggm)
sg.calculate_module_expression(adata_vi,ggm)
sg.calculate_module_expression(adata_hd,ggm)
sg.calculate_module_expression(adata_xe,ggm)
sg.calculate_module_expression(adata_sc,ggm)


# %%
# 计算模块注释
sg.calculate_gmm_annotations(adata_in_1,k_neighbors=6)
sg.calculate_gmm_annotations(adata_in_2,k_neighbors=6)
sg.calculate_gmm_annotations(adata_vi,k_neighbors=6)
sg.calculate_gmm_annotations(adata_hd,k_neighbors=8)
sg.calculate_gmm_annotations(adata_xe,k_neighbors=8)
sg.calculate_gmm_annotations(adata_sc,embedding_key='X_umap',k_neighbors=8)



# %%
# 添加对比
sg.calculate_module_expression(adata_in_1,ggm,ggm_key='new_moran')
sg.calculate_module_expression(adata_in_2,ggm,ggm_key='new_moran')
sg.calculate_module_expression(adata_vi,ggm,ggm_key='new_moran')
sg.calculate_module_expression(adata_hd,ggm,ggm_key='new_moran')
sg.calculate_module_expression(adata_xe,ggm,ggm_key='new_moran')
sg.calculate_module_expression(adata_sc,ggm,ggm_key='new_moran')    


# %%
# 新版函数
import scanpy as sc
import pandas as pd
import numpy as np
import scipy.sparse as sp
import networkx as nx
import matplotlib.pyplot as plt
import matplotlib as mpl
import itertools
import warnings
import leidenalg
import sys
import random
from sklearn.preprocessing import StandardScaler
from sklearn.mixture import GaussianMixture
from scipy.stats import skew, rankdata
from igraph import Graph
from sklearn.neighbors import NearestNeighbors, KernelDensity
from matplotlib import colors as mcolors
from scanpy.plotting.palettes import default_20, vega_10, vega_20
from matplotlib.lines import Line2D

# ----------------------------------------------------------------------
# 1. Squidpy-compatible spatial weights
# ----------------------------------------------------------------------
def construct_spatial_weights_rownorm(
    coords: np.ndarray,
    k_neighbors: int = 6,
    *,
    dtype=np.float32,
) -> sp.csr_matrix:
    """
    Memory-efficient, Squidpy-compatible k-NN spatial weight matrix (CSR).
    • 对称化一步到位，避免  W + W.T  的临时峰值
    • 行归一化直接在  W.data  原地缩放，不生成对角矩阵
    • 默认 float32，可选 float64
    """
    N = coords.shape[0]
    knn = NearestNeighbors(n_neighbors=k_neighbors, metric="euclidean").fit(coords)
    dists, idx = knn.kneighbors(coords)

    # 1/d  权重
    with np.errstate(divide="ignore"):  # 避免 0 距离
        weight = (1.0 / dists).astype(dtype)
    weight[dists == 0] = 0

    # ------------- 构建对称索引 -------------
    rows = np.repeat(np.arange(N), k_neighbors)
    cols = idx.reshape(-1)
    data = weight.reshape(-1)

    rows_sym = cols           # 反向边
    cols_sym = rows
    data_sym = data           # 权值相同

    rows = np.concatenate((rows, rows_sym))
    cols = np.concatenate((cols, rows_sym))  # ⚠️注意：cols_sym=rows
    data = np.concatenate((data, data_sym))

    W = sp.csr_matrix((data, (rows, cols)), shape=(N, N))
    W.sum_duplicates()        # 合并重复边
    W.setdiag(0)

    # ------------- 行归一化（就地） -------------
    row_sums = np.asarray(W.sum(axis=1)).ravel()
    nz_rows = row_sums != 0
    inv_row = np.zeros_like(row_sums, dtype=dtype)
    inv_row[nz_rows] = 1.0 / row_sums[nz_rows]

    # CSR 原地缩放：对每一行段 data[start:end] *= inv_row[i]
    for i in np.where(nz_rows)[0]:
        start, end = W.indptr[i], W.indptr[i + 1]
        W.data[start:end] *= inv_row[i]

    W.eliminate_zeros()
    return W

# ----------------------------------------------------------------------
# 2. Squidpy-compatible Moran’s I
# ----------------------------------------------------------------------
def moran_rowstandardized(x: np.ndarray, W: sp.csr_matrix) -> float:
    """
    Global Moran's I identical to esda.Moran when `W.transform == "r"`.

    Parameters
    ----------
    x : (N,) array-like
        Expression / score vector.
    W : csr_matrix
        Row-standardized spatial weight matrix (row sums == 1).

    Returns
    -------
    float
        Moran's I,  NaN if variance == 0.
    """
    x = np.asarray(x).ravel()
    z = x - x.mean()
    denom = np.dot(z, z)
    if denom == 0:
        return np.nan
    num = z @ (W @ z)
    return num / denom    # 因为 S0 == N 已被抵消


# ----------------------------------------------------------------------
# 3. 在主流程中调用
# ----------------------------------------------------------------------
# calculate_gmm_annotations_new
def calculate_gmm_annotations_new(adata, 
                              ggm_key='ggm',
                              modules_used=None,
                              modules_excluded=None,
                              calculate_moran=True,
                              embedding_key='spatial',
                              k_neighbors=6,
                              max_iter=200,
                              prob_threshold=0.99,
                              min_samples=10,
                              n_components=3,
                              enable_fallback=True,
                              random_state=42
                              ):
    """
    Gaussian Mixture Model annotation with additional module-level statistics.
    
    Statistics added to mod_stats_key include:
        - module_id: Module ID.
        - status: 'success' or 'failed'.
        - anno_one: Number of cells annotated as 1.
        - anno_zero: Number of cells expressed module but not annotated as 1.
        - skew: Skewness of the non-zero expression distribution for the module.
        - top1pct_ratio: Ratio of the average expression among the top 1% high-expressing cells
                        to the overall cells mean.
        - module_moran_I: Global Moran's I computed on the module expression (all cells) (if calculate_moran True).
        - positive_moran_I: Moran's I computed on module expression for cells annotated as 1 (if calculate_moran True).
        - negative_moran_I: Moran's I computed on module expression for cells annotated as 0 (if calculate_moran True).
        - n_components: Number of components in the GMM.
        - final_components: Number of components after fallback.
        - threshold: Threshold for calling a cell positive.
        - components: List of dictionaries with keys 'component', 'mean', 'var', 'weight'.
        - main_component: Index of the main component.
        - error_info: Error message if status is 'failed'.
        - top_go_terms: Top GO terms associated with the module.
    """

    # Retrieve keys from adata.uns['ggm_keys']
    ggm_keys = adata.uns.get('ggm_keys', {})
    if ggm_key not in ggm_keys:
        raise ValueError(f"{ggm_key} not found in adata.uns['ggm_keys']")
    mod_info_key = ggm_keys[ggm_key].get('module_info')
    mod_stats_key = ggm_keys[ggm_key].get('module_stats')
    expr_key = ggm_keys[ggm_key].get('module_expression')
    if expr_key not in adata.obsm:
        raise ValueError(f"{expr_key} not found in adata.obsm")
    if mod_info_key not in adata.uns:
        raise ValueError(f"{mod_info_key} not found in adata.uns")
    
    # Extract module expression matrix and module information
    module_expr_matrix = pd.DataFrame(adata.obsm[expr_key], index=adata.obs.index)
    unique_mods = adata.uns[mod_info_key]['module_id'].unique()
    if len(unique_mods) != module_expr_matrix.shape[1]:
        raise ValueError(f"module_info and module_expression dimensions for the ggm '{ggm_key}' do not match")
    else:
        module_expr_matrix.columns = unique_mods
    
    # Determine modules to use
    if modules_used is None and modules_excluded is None and mod_stats_key in adata.uns:
       adata.uns.pop(mod_stats_key, None)

    if modules_used is None:
        modules_used = list(unique_mods)
    if modules_excluded is not None:
        modules_used = [mid for mid in modules_used if mid not in modules_excluded]
    valid_modules = [mid for mid in modules_used if mid in module_expr_matrix.columns]
    if not valid_modules:
        raise ValueError(f"Ensure that the input module IDs exist in adata.uns['{mod_info_key}']")
    
    # Remove existing annotation columns
    for col in list(adata.obs.columns):
        if col.endswith('_anno') and any(col.startswith(mid) for mid in valid_modules):
            adata.obs.drop(columns=col, inplace=True)
        if col.endswith('_exp_trim') and any(col.startswith(mid) for mid in valid_modules):
            adata.obs.drop(columns=col, inplace=True)
        if col.endswith('_anno_smooth') and any(col.startswith(mid) for mid in valid_modules):
            adata.obs.drop(columns=col, inplace=True)    
    
    # Initialize annotation matrix (0/1) for modules
    anno_cols = valid_modules
    annotations = pd.DataFrame(np.zeros((adata.obs.shape[0], len(anno_cols)), dtype=int),
                               index=adata.obs.index, columns=anno_cols)
    stats_records = []
    
    # Pre-calculate expression ranking for tie-breaks
    expr_score = {}
    for mid in valid_modules:
        module_col = f"{mid}_exp"
        if module_col not in adata.obs.columns:
            raise KeyError(f"'{module_col}' not found in adata.obs.")
        rank_vals = adata.obs[module_col].rank(method='dense', ascending=False).astype(int)
        expr_score[mid] = rank_vals.values
    
    # If calculate_moran is True, construct spatial weights matrix W based on embedding_key.
    if calculate_moran:
        if embedding_key not in adata.obsm:
            raise ValueError(f"{embedding_key} not found in adata.obsm")
        coords = adata.obsm[embedding_key]
        W = construct_spatial_weights_rownorm(coords, k_neighbors=k_neighbors)
    else:
        coords = None
        W = None
    
    # Build mapping from gene to index using adata.var_names
    gene_to_index = {gene: i for i, gene in enumerate(adata.var_names)}
    
    # Process each module for GMM annotation and extra statistics
    for module_id in valid_modules:
        stats = {
            'module_id': module_id,
            'status': 'success',
            'n_components': n_components,
            'final_components': n_components,
            'threshold': np.nan,
            'anno_one': 0,
            'anno_zero': 0,
            'components': [],
            'error_info': 'None',
            'module_moran_I': np.nan,
            'positive_moran_I': np.nan,
            'negative_moran_I': np.nan,
            'skew': np.nan,
            'top1pct_ratio': np.nan,
            'effect_size': np.nan
        }
        try:
            expr_values = module_expr_matrix[module_id].values
            non_zero_mask = expr_values != 0
            non_zero_expr = expr_values[non_zero_mask]
            if len(non_zero_expr) == 0:
                raise ValueError("all_zero_expression")
            if len(non_zero_expr) < min_samples:
                raise ValueError(f"insufficient_samples ({len(non_zero_expr)} < {min_samples})")
            if np.var(non_zero_expr) < 1e-6:
                raise ValueError("zero_variance")
            
            # Fit GMM on non-zero expression
            gmm = GaussianMixture(n_components=n_components, random_state=random_state, max_iter=max_iter)
            with warnings.catch_warnings():
                warnings.filterwarnings("ignore")
                gmm.fit(non_zero_expr.reshape(-1, 1))
            means = gmm.means_.flatten()
            main_component = int(np.argmax(means))
            main_mean = means[main_component]
            probs = gmm.predict_proba(non_zero_expr.reshape(-1, 1))[:, main_component]
            anno_non_zero = (probs >= prob_threshold).astype(int)
            if np.sum(anno_non_zero) == 0:
                raise ValueError("no_positive_cells")
            positive_expr = non_zero_expr[anno_non_zero == 1]
            threshold = float(np.min(positive_expr))
            if n_components >= 3 and threshold > main_mean:
                raise ValueError(f"threshold {threshold:.2f} > μ ({main_mean:.2f})")
            stats.update({
                'threshold': threshold,
                'anno_one': int(np.sum(anno_non_zero)),
                'anno_zero': int(len(anno_non_zero) - np.sum(anno_non_zero)),
                'components': [
                    {'component': i,
                     'mean': float(gmm.means_[i][0]),
                     'var': float(gmm.covariances_[i][0][0]),
                     'weight': float(gmm.weights_[i])
                    } for i in range(n_components)
                ],
                'main_component': main_component
            })
            
            # Build full annotation vector for module: default 0, update non-zero positions
            module_annotation = np.zeros_like(expr_values, dtype=int)
            module_annotation[non_zero_mask] = anno_non_zero
            annotations[module_id] = module_annotation
            
            # Calculate additional statistics
            if calculate_moran:
                mod_I = moran_rowstandardized(expr_values, W)
                stats['module_moran_I'] = mod_I
                
                pos_expr_masked = np.where(module_annotation == 1, expr_values, 0)
                stats['positive_moran_I'] = moran_rowstandardized(pos_expr_masked, W)
                
                neg_expr_masked = np.where(module_annotation == 0, expr_values, 0)
                stats['negative_moran_I'] = moran_rowstandardized(neg_expr_masked, W)
            else:
                stats['module_moran_I'] = np.nan
                stats['positive_moran_I'] = np.nan
                stats['negative_moran_I'] = np.nan
            
            stats['skew'] = float(skew(non_zero_expr))
            
            if len(expr_values) > 0:
                top_n = max(1, int(len(expr_values) * 0.01))
                sorted_expr = np.sort(expr_values)
                top1_mean = np.mean(sorted_expr[-top_n:])
                overall_mean = np.mean(expr_values)
                stats['top1pct_ratio'] = top1_mean / overall_mean if overall_mean != 0 else np.nan
            else:
                stats['top1pct_ratio'] = np.nan
            
            if len(positive_expr) > 0:
                std_all = np.std(non_zero_expr)
                neg_expr = non_zero_expr[anno_non_zero == 0]
                stats['effect_size'] = float(np.mean(positive_expr) - np.mean(neg_expr)) / std_all if std_all != 0 else np.nan
            else:
                stats['effect_size'] = np.nan
            
        except Exception as e:
            stats.update({
                'status': 'failed',
                'error_info': str(e),
                'components': [],
                'threshold': np.nan,
                'anno_one': 0,
                'anno_zero': expr_values.size if 'expr_values' in locals() else 0,
                'module_moran_I': np.nan,
                'positive_moran_I': np.nan,
                'negative_moran_I': np.nan,
                'skew': np.nan,
                'top1pct_ratio': np.nan,
                'effect_size': np.nan
            })
            if enable_fallback and n_components > 2:
                try:
                    gmm = GaussianMixture(n_components=2, random_state=random_state, max_iter=max_iter)
                    gmm.fit(non_zero_expr.reshape(-1, 1))
                    means = gmm.means_.flatten()
                    main_component = int(np.argmax(means))
                    probs = gmm.predict_proba(non_zero_expr.reshape(-1, 1))[:, main_component]
                    anno_non_zero = (probs >= ((1 - (1 - prob_threshold) * 1e-2))).astype(int)
                    if np.sum(anno_non_zero) > 0:
                        positive_expr = non_zero_expr[anno_non_zero == 1]
                        threshold = float(np.min(positive_expr))
                        stats.update({
                            'status': 'success',
                            'final_components': 2,
                            'threshold': threshold,
                            'anno_one': int(np.sum(anno_non_zero)),
                            'anno_zero': int(len(anno_non_zero) - np.sum(anno_non_zero)),
                            'components': [
                                {'component': 0,
                                 'mean': float(gmm.means_[0][0]),
                                 'var': float(gmm.covariances_[0][0][0]),
                                 'weight': float(gmm.weights_[0])
                                },
                                {'component': 1,
                                 'mean': float(gmm.means_[1][0]),
                                 'var': float(gmm.covariances_[1][0][0]),
                                 'weight': float(gmm.weights_[1])
                                }
                            ],
                            'main_component': main_component
                        })
                        fallback_annotation = np.zeros_like(expr_values, dtype=int)
                        fallback_annotation[non_zero_mask] = anno_non_zero
                        annotations.loc[non_zero_mask, module_id] = anno_non_zero
                        if calculate_moran:
                            fallback_mod_I = moran_rowstandardized(expr_values, W)
                            stats['module_moran_I'] = fallback_mod_I
                            pos_expr_masked = np.where(fallback_annotation == 1, expr_values, 0)
                            stats['positive_moran_I'] = moran_rowstandardized(pos_expr_masked, W)
                            neg_expr_masked = np.where(fallback_annotation == 0, expr_values, 0)
                            stats['negative_moran_I'] = moran_rowstandardized(neg_expr_masked, W)
                        else:
                            stats['module_moran_I'] = np.nan
                            stats['positive_moran_I'] = np.nan
                            stats['negative_moran_I'] = np.nan
                        stats['skew'] = float(skew(non_zero_expr))
                        if len(non_zero_expr) > 0:
                            top_n = max(1, int(len(non_zero_expr) * 0.01))
                            sorted_expr = np.sort(non_zero_expr)
                            top1_mean = np.mean(sorted_expr[-top_n:])
                            overall_mean = np.mean(non_zero_expr)
                            stats['top1pct_ratio'] = top1_mean / overall_mean if overall_mean != 0 else np.nan
                        else:
                            stats['top1pct_ratio'] = np.nan
                        if len(positive_expr) > 0:
                            std_all = np.std(non_zero_expr)
                            neg_expr = non_zero_expr[anno_non_zero == 0]
                            stats['effect_size'] = float(np.mean(positive_expr) - np.mean(neg_expr)) / std_all if std_all != 0 else np.nan
                        else:
                            stats['effect_size'] = np.nan
                except Exception as fallback_e:
                    stats['error_info'] += f"; Fallback failed: {str(fallback_e)}"
        finally:
            if stats['status'] == 'success':
                print(f"{module_id} processed successfully, annotated cells: {stats['anno_one']}")
            else:
                print(f"{module_id} processed, failed: {stats['error_info']}")
            stats['components'] = str(stats['components'])
            stats_records.append(stats)
    
    # Transform annotations to categorical and store in adata.obs
    annotations.columns = [f"{col}_anno" for col in annotations.columns]
    for col in annotations.columns:
        orig_name = col.replace("_anno", "")
        annotations[col] = np.where(annotations[col] == 1, orig_name, None)
        annotations[col] = pd.Categorical(annotations[col])
    adata.obs = pd.concat([adata.obs, annotations], axis=1)
    
    # Add trimmed expression columns which are 0 if the annotation is None for this module
    trim_dict = {}
    for mod in valid_modules:
        exp_col = f"{mod}_exp"
        anno_col = f"{mod}_anno"
        trim_col = f"{mod}_exp_trim"
        if exp_col in adata.obs and anno_col in adata.obs:
            mask = (adata.obs[anno_col] == mod).astype(int)
            trim_dict[trim_col] = adata.obs[exp_col] * mask

    if trim_dict:
        trim_df = pd.DataFrame(trim_dict, index=adata.obs.index)
        adata.obs = pd.concat([adata.obs, trim_df], axis=1)

    # Add GO annotations to module_stats_key 
    stats_records_df = pd.DataFrame(stats_records)
    module_info_df = adata.uns[mod_info_key]
    go_cols = [col for col in module_info_df.columns if col.startswith("top_") and col.endswith("_go_term")]
    if len(go_cols) > 0:
        def concat_go_terms(mod_id):
            rows = module_info_df[module_info_df['module_id'] == mod_id]
            terms = []
            for col in go_cols:
                vals = rows[col].dropna().unique().tolist()
                if vals:
                    terms.extend(vals)
            if terms:
                return " || ".join(sorted(set(terms)))
            else:
                return ""
        stats_records_df["top_go_terms"] = stats_records_df["module_id"].apply(concat_go_terms)
        new_order = [
            'module_id', 'status', 'anno_one', 'anno_zero', 'top_go_terms', 'skew', 'top1pct_ratio', 
            'module_moran_I', 'positive_moran_I', 'negative_moran_I', 'effect_size',
            'n_components', 'final_components','threshold', 'components', 'main_component', 'error_info']
        stats_records_df = stats_records_df[new_order]
    else:
        new_order = [
            'module_id', 'status', 'anno_one', 'anno_zero', 'skew', 'top1pct_ratio',
            'module_moran_I', 'positive_moran_I', 'negative_moran_I', 'effect_size',
            'n_components', 'final_components','threshold', 'components', 'main_component', 'error_info']
        stats_records_df = stats_records_df[new_order]
    
    if mod_stats_key in adata.uns:
        existing_stats = adata.uns[mod_stats_key]
        for mid in stats_records_df['module_id'].unique():
            new_row = stats_records_df.loc[stats_records_df['module_id'] == mid].iloc[0]
            mask = existing_stats['module_id'] == mid
            if mask.any():
                num_rows = mask.sum()
                new_update_df = pd.DataFrame([new_row] * num_rows, index=existing_stats.loc[mask].index)
                existing_stats.loc[mask] = new_update_df
            else:
                existing_stats = pd.concat([existing_stats, pd.DataFrame([new_row])], ignore_index=True)
        existing_stats.dropna(how='all', inplace=True)
        adata.uns[mod_stats_key] = existing_stats
    else:
        adata.uns[mod_stats_key] = stats_records_df

        


# %%
calculate_gmm_annotations_new(adata_in_1,ggm_key='new_moran',k_neighbors=6)
calculate_gmm_annotations_new(adata_in_2,ggm_key='new_moran',k_neighbors=6)
calculate_gmm_annotations_new(adata_vi,ggm_key='new_moran',k_neighbors=6)
calculate_gmm_annotations_new(adata_hd,ggm_key='new_moran',k_neighbors=8)
calculate_gmm_annotations_new(adata_xe,ggm_key='new_moran',k_neighbors=8)
calculate_gmm_annotations_new(adata_sc,ggm_key='new_moran',embedding_key='X_umap',k_neighbors=8)


# %%
adata_in_1.uns['module_stats']['module_moran_I'].describe()

# %%
adata_in_1.uns['new_moran_module_stats']['module_moran_I'].describe()


# %%
adata_in_1.uns['module_stats']['module_moran_I']

# %%
adata_in_1.uns['new_moran_module_stats']['module_moran_I']

# %%
adata_sc.uns['module_stats']['module_moran_I'].describe()

# %%
adata_sc.uns['new_moran_module_stats']['module_moran_I'].describe()





# %%
old_moran = adata_in_1.uns['module_stats']['module_moran_I'].values
new_moran = adata_in_1.uns['new_moran_module_stats']['module_moran_I'].values
sc_moran_diff = pd.DataFrame({
    'module_id': adata_in_1.uns['module_stats']['module_id'].values,
    'old_moran': old_moran,
    'new_moran': new_moran,
    'diff': new_moran - old_moran,
})
sc_moran_diff['mean_diff'] = sc_moran_diff['diff'][sc_moran_diff['diff'] != None].mean()
sc_moran_diff.to_csv('results/Fig4/Visium_Mouse_Brain_Multi_Union_r3_in_1_moran_diff.csv', index=False)

# %%
old_moran = adata_in_2.uns['module_stats']['module_moran_I'].values
new_moran = adata_in_2.uns['new_moran_module_stats']['module_moran_I'].values
sc_moran_diff = pd.DataFrame({
    'module_id': adata_in_2.uns['module_stats']['module_id'].values,
    'old_moran': old_moran,
    'new_moran': new_moran,
    'diff': new_moran - old_moran,
})
sc_moran_diff['mean_diff'] = sc_moran_diff['diff'][sc_moran_diff['diff'] != None].mean()
sc_moran_diff.to_csv('results/Fig4/Visium_Mouse_Brain_Multi_Union_r3_in_2_moran_diff.csv', index=False)

# %%
old_moran = adata_vi.uns['module_stats']['module_moran_I'].values
new_moran = adata_vi.uns['new_moran_module_stats']['module_moran_I'].values
sc_moran_diff = pd.DataFrame({
    'module_id': adata_vi.uns['module_stats']['module_id'].values,
    'old_moran': old_moran,
    'new_moran': new_moran,
    'diff': new_moran - old_moran,
})
sc_moran_diff['mean_diff'] = sc_moran_diff['diff'][sc_moran_diff['diff'] != None].mean()
sc_moran_diff.to_csv('results/Fig4/Visium_Mouse_Brain_Multi_Union_r3_vi_moran_diff.csv', index=False)

# %%
old_moran = adata_hd.uns['module_stats']['module_moran_I'].values
new_moran = adata_hd.uns['new_moran_module_stats']['module_moran_I'].values
sc_moran_diff = pd.DataFrame({
    'module_id': adata_hd.uns['module_stats']['module_id'].values,
    'old_moran': old_moran,
    'new_moran': new_moran,
    'diff': new_moran - old_moran,
})
sc_moran_diff['mean_diff'] = sc_moran_diff['diff'][sc_moran_diff['diff'] != None].mean()
sc_moran_diff.to_csv('results/Fig4/Visium_Mouse_Brain_Multi_Union_r3_hd_moran_diff.csv', index=False)

# %%
old_moran = adata_xe.uns['module_stats']['module_moran_I'].values
new_moran = adata_xe.uns['new_moran_module_stats']['module_moran_I'].values
sc_moran_diff = pd.DataFrame({
    'module_id': adata_xe.uns['module_stats']['module_id'].values,
    'old_moran': old_moran,
    'new_moran': new_moran,
    'diff': new_moran - old_moran,
})
sc_moran_diff['mean_diff'] = sc_moran_diff['diff'][sc_moran_diff['diff'] != None].mean()
sc_moran_diff.to_csv('results/Fig4/Visium_Mouse_Brain_Multi_Union_r3_xe_moran_diff.csv', index=False)

# %%
old_moran = adata_sc.uns['module_stats']['module_moran_I'].values
new_moran = adata_sc.uns['new_moran_module_stats']['module_moran_I'].values
sc_moran_diff = pd.DataFrame({
    'module_id': adata_sc.uns['module_stats']['module_id'].values,
    'old_moran': old_moran,
    'new_moran': new_moran,
    'diff': new_moran - old_moran,
})
sc_moran_diff['mean_diff'] = sc_moran_diff['diff'][sc_moran_diff['diff'] != None].mean()
sc_moran_diff.to_csv('results/Fig4/Visium_Mouse_Brain_Multi_Union_r3_sc_moran_diff.csv', index=False)



# %%


